version: "3.8"

services:
  # Hadoop Namenode (Public image placeholder)
  namenode:
    image: hadoop-namenode:public
    container_name: namenode
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    env_file:
      - ./environment.env
    environment:
      - CLUSTER_NAME=dev_delta
    networks:
      - test_network

  # Hadoop Datanode (Public image placeholder)
  datanode:
    image: hadoop-datanode:public
    container_name: datanode
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    env_file:
      - ./environment.env
    environment:
      - SERVICE_PRECONDITION=namenode:9870
    networks:
      - test_network
    depends_on:
      - namenode

  # Hue Web UI for Hadoop
  hue:
    image: gethue/hue:20230822-140101
    container_name: hue
    ports:
      - "8888:8888"
    volumes:
      - ./hue.ini:/usr/share/hue/desktop/conf/hue.ini
      - ./z-hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue-overrides.ini
    networks:
      - test_network
    depends_on:
      - namenode
      - datanode

  # Spark Master Node
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "7077:7077"
      - "8082:8080"
    volumes:
      - ./spark-submit:/opt/spark-submit
    networks:
      - test_network

  # Spark Worker Node
  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    ports:
      - "8081:8081"
    volumes:
      - ./spark-submit:/opt/spark-submit
    networks:
      - test_network
    depends_on:
      - spark-master

  # Apache NiFi
  nifi:
    image: apache/nifi:1.15.3
    container_name: nifi
    ports:
      - "8080:8080"
    volumes:
      - nifi_certs:/opt/certs
      - nifi_conf:/opt/nifi/nifi-current/conf
      - nifi_extensions:/opt/nifi/nifi-current/extensions
      - nifi_database_repository:/opt/nifi/nifi-current/database_repository
      - nifi_flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      - nifi_content_repository:/opt/nifi/nifi-current/content_repository
      - nifi_provenance_repository:/opt/nifi/nifi-current/provenance_repository
      - nifi_state:/opt/nifi/nifi-current/state
      - nifi_logs:/opt/nifi/nifi-current/logs
      - ./data:/opt/nifi/data
    environment:
      - NIFI_WEB_HTTP_PORT=8080
    networks:
      - test_network
    depends_on:
      - namenode
      - datanode
      - spark-master

  # PostgreSQL for Weather Project
  postgres-db:
    image: postgres:14
    container_name: postgres-db
    ports:
      - "5432:5432"
    env_file:
      - ./environment.env
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - test_network

  # PostgreSQL for Airflow
  postgres-airflow:
    image: postgres:14
    container_name: postgres-airflow
    ports:
      - "5435:5432"
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow_db
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data
    networks:
      - test_network

  # Airflow Webserver
  airflow-webserver:
    image: apache/airflow:latest
    container_name: airflow-webserver
    user: root
    restart: always
    depends_on:
      - postgres-airflow
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow_db
      - AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8282:8080"
    command: webserver
    networks:
      - test_network

  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:latest
    container_name: airflow-scheduler
    user: root
    restart: always
    depends_on:
      - postgres-airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow_db
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    networks:
      - test_network

  # Apache Zookeeper
  zoo1:
    image: zookeeper:latest
    container_name: zoo1
    ports:
      - "2182:2181"
    environment:
      - ZOO_MY_ID=1
      - ZOO_CLIENT_PORT=2181
      - ZOO_STANDALONE_ENABLED=true
    volumes:
      - zoo1:/data
      - zoo1log:/datalog
    networks:
      - test_network

  # Apache Kafka
  kafka1:
    image: bitnami/kafka:latest
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zoo1:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - ./kafka-data:/bitnami/kafka
    depends_on:
      - zoo1
    networks:
      - test_network

  # Metabase Dashboard
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    ports:
      - "3000:3000"
    env_file:
      - ./environment.env
    depends_on:
      - postgres-db
    networks:
      - test_network

volumes:
  hadoop_namenode:
  hadoop_datanode:
  nifi_certs:
  nifi_conf:
  nifi_extensions:
  nifi_database_repository:
  nifi_flowfile_repository:
  nifi_content_repository:
  nifi_provenance_repository:
  nifi_state:
  nifi_logs:
  postgres_data:
  postgres_airflow_data:
  kafka-data:
  zoo1:
  zoo1log:

networks:
  test_network:
